{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = 16\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"constant\"):\n",
    "    t = tf.placeholder(tf.float64, shape=())\n",
    "    H = tf.reshape(tf.constant([[0.25,0,0,0],[0,-0.25,0.5,0],[0,0.5,-0.25,0],[0,0,0,0.25]],\n",
    "                               dtype=tf.float64),[2,2,2,2],name=\"Hamiltonian\")\n",
    "    I = tf.reshape(tf.constant([[1.,0,0,0],[0,1,0,0],[0,0,1,0],[0,0,0,1]],\n",
    "                               dtype=tf.float64),[2,2,2,2],name=\"Identity\")\n",
    "    expH = I + t * H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"variables\"):\n",
    "    A = tf.placeholder(shape=[D, D, 2], dtype=tf.float64,name=\"A\")\n",
    "    B = tf.placeholder(shape=[D, D, 2], dtype=tf.float64, name=\"B\")\n",
    "    EAB = tf.placeholder(shape=[D], dtype=tf.float64, name=\"EAB\")\n",
    "    EBA = tf.placeholder(shape=[D], dtype=tf.float64, name=\"EBA\")\n",
    "    L = tf.placeholder(shape=[D, D], dtype=tf.float64, name=\"L\")\n",
    "    R = tf.placeholder(shape=[D, D], dtype=tf.float64, name=\"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"parameter\"):\n",
    "    REAB = tf.reciprocal(EAB,name=\"REAB\")\n",
    "    REBA = tf.reciprocal(EBA,name=\"REBA\")\n",
    "    \n",
    "    EA = tf.multiply(tf.multiply(A,tf.reshape(EBA,[D,1,1])),tf.reshape(EAB,[1,D,1]),name=\"EA\")\n",
    "    EB = tf.multiply(tf.multiply(B,tf.reshape(EAB,[D,1,1])),tf.reshape(EBA,[1,D,1]),name=\"EB\")\n",
    "    \n",
    "    AB = tf.tensordot(EA,EB,[[1],[0]],name=\"AB\")\n",
    "    BA = tf.tensordot(EB,EA,[[1],[0]],name=\"BA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_max(t):\n",
    "    with tf.name_scope(\"d_max\"):\n",
    "        return t/tf.reduce_max(tf.abs(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"updateAB\"):\n",
    "    HAB = tf.tensordot(AB,expH,[[1,3],[0,1]],name=\"HAB\")\n",
    "    S, U, V = tf.svd(tf.reshape(tf.transpose(HAB,[0,2,1,3]),[2*D,2*D]))\n",
    "    ABnEAB = tf.sqrt(S[:D],name=\"nE\")\n",
    "    ABnA = tf.transpose(tf.multiply(tf.reshape(U[:,:D],[D,2,D]),tf.reshape(REBA,[D,1,1])),[0,2,1],name=\"nA\")\n",
    "    ABnB = tf.transpose(tf.multiply(tf.reshape(V[:,:D],[D,2,D]),tf.reshape(REBA,[D,1,1])),[2,0,1],name=\"nB\")\n",
    "    updateAB = tf.tuple((d_max(ABnEAB),d_max(ABnA),d_max(ABnB)),name=\"updateAB\")\n",
    "\n",
    "with tf.name_scope(\"updateBA\"):\n",
    "    HBA = tf.tensordot(BA,expH,[[1,3],[0,1]],name=\"HBA\")\n",
    "    S, U, V = tf.svd(tf.reshape(tf.transpose(HBA,[0,2,1,3]),[2*D,2*D]))\n",
    "    BAnEBA = tf.sqrt(S[:D],name=\"nE\")\n",
    "    BAnB = tf.transpose(tf.multiply(tf.reshape(U[:,:D],[D,2,D]),tf.reshape(REAB,[D,1,1])),[0,2,1],name=\"nB\")\n",
    "    BAnA = tf.transpose(tf.multiply(tf.reshape(V[:,:D],[D,2,D]),tf.reshape(REAB,[D,1,1])),[2,0,1],name=\"nA\")\n",
    "    updateBA = tf.tuple((d_max(BAnEBA),d_max(BAnB),d_max(BAnA)),name=\"updateBA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"updateL\"):\n",
    "    LA = tf.tensordot(tf.tensordot(L,EA,[[1],[0]]),EA,[[0,2],[0,2]],name=\"LA\")\n",
    "    LAB = tf.tensordot(tf.tensordot(LA,EB,[[1],[0]]),EB,[[0,2],[0,2]],name=\"LAB\")\n",
    "    \n",
    "    updateL = d_max(LAB)\n",
    "        \n",
    "with tf.name_scope(\"updateR\"):\n",
    "    BR = tf.tensordot(tf.tensordot(R,EB,[[1],[1]]),EB,[[0,2],[1,2]],name=\"BR\")\n",
    "    ABR = tf.tensordot(tf.tensordot(BR,EA,[[1],[1]]),EA,[[0,2],[1,2]],name=\"ABR\")\n",
    "    updateR = d_max(ABR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Energy\"):\n",
    "    LA = tf.tensordot(L,EA,[[0],[0]])\n",
    "    LAB = tf.tensordot(LA,EB,[[1],[0]])\n",
    "    LABR = tf.tensordot(LAB,R,[[2],[0]])\n",
    "    LABRA = tf.tensordot(LABR,EA,[[0],[0]])\n",
    "    LABRAB = tf.tensordot(LABRA,EB,[[3,2],[0,1]])\n",
    "    E_AB = tf.tensordot(LABRAB,H,[[0,1,2,3],[0,1,2,3]])/tf.tensordot(LABRAB,I,[[0,1,2,3],[0,1,2,3]])\n",
    "\n",
    "    LABA = tf.tensordot(LAB,EA,[[2],[0]])\n",
    "    LABAA = tf.tensordot(LABA,EA,[[0,1],[0,2]])\n",
    "    LABAAB = tf.tensordot(LABAA,EB,[[3],[0]])\n",
    "    LABAABA = tf.tensordot(LABAAB,EA,[[3],[0]])\n",
    "    LABAABAB = tf.tensordot(LABAABA,EB,[[4],[0]])\n",
    "    LABAABABB = tf.tensordot(LABAABAB,EB,[[1,6],[0,2]])\n",
    "    LABAABABBR = tf.tensordot(LABAABABB,R,[[5,4],[0,1]])\n",
    "    E_BA = tf.tensordot(LABAABABBR,H,[[0,1,2,3],[0,1,2,3]])/tf.tensordot(LABAABABBR,I,[[0,1,2,3],[0,1,2,3]])\n",
    "\n",
    "    E = (E_AB+E_BA)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.add_to_collection(\"t\",t)\n",
    "tf.add_to_collection(\"A\",A)\n",
    "tf.add_to_collection(\"B\",B)\n",
    "tf.add_to_collection(\"EAB\",EAB)\n",
    "tf.add_to_collection(\"EBA\",EBA)\n",
    "tf.add_to_collection(\"L\",L)\n",
    "tf.add_to_collection(\"R\",R)\n",
    "tf.add_to_collection(\"updateAB\",updateAB[0])\n",
    "tf.add_to_collection(\"updateAB\",updateAB[1])\n",
    "tf.add_to_collection(\"updateAB\",updateAB[2])\n",
    "tf.add_to_collection(\"updateBA\",updateBA[0])\n",
    "tf.add_to_collection(\"updateBA\",updateBA[1])\n",
    "tf.add_to_collection(\"updateBA\",updateBA[2])\n",
    "tf.add_to_collection(\"updateL\",updateL)\n",
    "tf.add_to_collection(\"updateR\",updateR)\n",
    "tf.add_to_collection(\"E\",E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_graph_def = tf.train.export_meta_graph(filename='./MPS-%d.pbtxt'%D, as_text=True)\n",
    "file_writer = tf.summary.FileWriter('.', tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MPS():\n",
    "    def __init__(self,D):\n",
    "        self.sess = tf.get_default_session()\n",
    "        self.g = tf.get_default_graph()\n",
    "        tf.train.import_meta_graph(\"./MPS-%d.pbtxt\"%D)\n",
    "        self.dA = np.random.random([D,D,2])\n",
    "        self.dB = np.random.random([D,D,2])\n",
    "        self.dEAB = np.ones([D])\n",
    "        self.dEBA = np.ones([D])\n",
    "        self.dL = np.random.random([D,D])\n",
    "        self.dR = np.random.random([D,D])\n",
    "        self.ep = 0.1\n",
    "        self.t = self.g.get_collection(\"t\")[-1]\n",
    "        self.A = self.g.get_collection(\"A\")[-1]\n",
    "        self.B = self.g.get_collection(\"B\")[-1]\n",
    "        self.EAB = self.g.get_collection(\"EAB\")[-1]\n",
    "        self.EBA = self.g.get_collection(\"EBA\")[-1]\n",
    "        self.L = self.g.get_collection(\"L\")[-1]\n",
    "        self.R = self.g.get_collection(\"R\")[-1]\n",
    "        self.updateAB = self.g.get_collection(\"updateAB\")[-3:]\n",
    "        self.updateBA = self.g.get_collection(\"updateBA\")[-3:]\n",
    "        self.updateL = self.g.get_collection(\"updateL\")[-1]\n",
    "        self.updateR = self.g.get_collection(\"updateR\")[-1]\n",
    "        self.E = self.g.get_collection(\"E\")[-1]\n",
    "\n",
    "    def run_updateAB(self):\n",
    "        self.dEAB, self.dA, self.dB = self.sess.run(self.updateAB,feed_dict={\n",
    "            self.t:-4*self.ep, self.A:self.dA, self.B:self.dB, self.EAB:self.dEAB, self.EBA:self.dEBA})\n",
    "    def run_updateBA(self):\n",
    "        self.dEBA, self.dB, self.dA = self.sess.run(self.updateBA,feed_dict={\n",
    "            self.t:-4*self.ep, self.A:self.dA, self.B:self.dB, self.EAB:self.dEAB, self.EBA:self.dEBA})\n",
    "    def run_updateL(self):\n",
    "        self.dL = self.sess.run(self.updateL,feed_dict={\n",
    "            self.A:self.dA, self.B:self.dB, self.EAB:self.dEAB, self.EBA:self.dEBA, self.L:self.dL})\n",
    "    def run_updateR(self):\n",
    "        self.dR = self.sess.run(self.updateR,feed_dict={\n",
    "            self.A:self.dA, self.B:self.dB, self.EAB:self.dEAB, self.EBA:self.dEBA, self.R:self.dR})\n",
    "    def get_energy(self):\n",
    "        return self.sess.run(self.E,feed_dict={\n",
    "            self.A:self.dA, self.B:self.dB, self.EAB:self.dEAB, self.EBA:self.dEBA, self.L:self.dL, self.R:self.dR})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(), tf.Session().as_default():\n",
    "    mps = MPS(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.435446630909\n",
      "-0.435959017232\n",
      "-0.43586721527\n",
      "-0.435862814711\n",
      "-0.435862188572\n",
      "-0.435861199471\n",
      "-0.435861609592\n",
      "-0.435861508722\n",
      "-0.435861442868\n",
      "-0.435861432298\n",
      "CPU times: user 16.1 s, sys: 1.32 s, total: 17.4 s\n",
      "Wall time: 9.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in xrange(10):\n",
    "    for _ in xrange(100):\n",
    "        mps.run_updateAB()\n",
    "        mps.run_updateBA()\n",
    "        mps.run_updateBA()\n",
    "        mps.run_updateAB()\n",
    "    tmp = 0\n",
    "    #while abs(mps.get_energy()-tmp)>0.01:\n",
    "    for _ in [0]:\n",
    "        for _ in xrange(100):\n",
    "            mps.run_updateL()\n",
    "            mps.run_updateR()\n",
    "        tmp = mps.get_energy()\n",
    "    print tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
